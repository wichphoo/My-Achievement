# -*- coding: utf-8 -*-
"""Ztier_predict_NB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ewe1h6-GdMpHd4NFqJtDVHFjzfzVM56K
"""

from sklearn.feature_extraction import DictVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import ComplementNB
from sklearn.naive_bayes import CategoricalNB
from sklearn.naive_bayes import BernoulliNB

import numpy as np
import os
import pandas as pd
from sklearn.model_selection import train_test_split
import pathlib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_classification
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import RobustScaler
from sklearn import metrics
from sklearn.preprocessing import Normalizer
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import cross_val_score

"""Import"""

from google.colab import files
uploaded = files.upload()

import io
df = pd.read_csv(io.BytesIO(uploaded['Ztier_total.csv']))

#df.info()

#df.head()

"""Data Prep"""

del df['MerchantID']
#convert object to float64
df['Average - Short-Term Debt/Equity'] = pd.to_numeric(df['Average - Short-Term Debt/Equity'], errors='coerce')
df['Average - Cash/Net Sales'] = pd.to_numeric(df['Average - Cash/Net Sales'], errors='coerce')
df['Average - Ebit/Sales'] = pd.to_numeric(df['Average - Ebit/Sales'], errors='coerce')
df['Average - Net Income/Sales'] = pd.to_numeric(df['Average - Net Income/Sales'], errors='coerce')
df['Average - Ebitda/Interest Expense'] = pd.to_numeric(df['Average - Ebitda/Interest Expense'], errors='coerce')
df['Average - Ebit/Interest Expenses'] = pd.to_numeric(df['Average - Ebit/Interest Expenses'], errors='coerce')
df['Average - Account Payable/Sales'] = pd.to_numeric(df['Average - Account Payable/Sales'], errors='coerce')
df = df.fillna(0)

df2=df

#Convert -1 to 0 in target column 
df2['Z-score Tier'].replace({-1:0}, inplace=True)

#Create df2 with Normalize data
cols_to_normalize=df2.columns[0:29]

col_values=df2[cols_to_normalize].values

#Choose normalizer
#col_scaled=Normalizer().fit_transform(col_values)
col_scaled=RobustScaler().fit_transform(col_values)
#col_scaled=MinMaxScaler().fit_transform(col_values)
#col_scaled=StandardScaler().fit_transform(col_values)

df2[cols_to_normalize]=pd.DataFrame(col_scaled,columns=cols_to_normalize)

#check normalize ?
df2.agg(['min', 'max','mean'])

"""Model"""

#Split train&test dataset
X=df2[df2.columns[0:29]]

y=df2[df2.columns[-1:]]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)

#Choose one
#clf = MultinomialNB(alpha=1, class_prior=None, fit_prior=False)
#clf = GaussianNB()
#clf = ComplementNB(alpha=1, class_prior=None, fit_prior=False, norm=False)
#clf = CategoricalNB()
clf = BernoulliNB(fit_prior=False)

clfCV = cross_val_score(clf, X_train, y_train, cv=10)

clfCV

np.mean(clfCV)

clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)

print("Test accuracy: %0.5f" % clf.score(X_test, y_test))

"""Save Model"""

from sklearn.externals import joblib

joblib_file = "NB_model.pt"  
joblib.dump(clf, joblib_file)

from google.colab import files
files.download('NB_model.pt')

model_save()

import torch





"""Prediction"""

#Prediction probability
pre_proba = clf.predict_proba(X)

y_predall = clf.predict(X)

#Performance
conf=metrics.confusion_matrix(y, y_predall)

conf=pd.DataFrame(conf)
conf

print(metrics.classification_report(y, y_predall))

#Make Prediction table & Export csv

pre_proba = pd.DataFrame(pre_proba)

pre_proba1 = pre_proba[0].values.tolist()

#pre_proba = clf.predict_proba(X) again
pre_proba2 = pre_proba[1].values.tolist()

y_predall = y_predall.tolist()

y_testall = y['Z-score Tier'].values.tolist()

#Recall merchantID to make prediction table
import io
df = pd.read_csv(io.BytesIO(uploaded['Ztier_total.csv']))
dfwithID = df

ID = dfwithID['MerchantID'].tolist()

dataframe = pd.DataFrame([ID, y_testall, y_predall, pre_proba1, pre_proba2], index =['MerchantID', 'y_actual', 'y_predict', 'Predict_Prob(0)', 'Predict_Prob(1)'])

dataframe = dataframe.T

dataframe.to_csv('Prediction NB.csv')

from google.colab import files
files.download('Prediction NB.csv')

from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
from sklearn.metrics import plot_roc_curve
from matplotlib import pyplot
from matplotlib import pyplot as plt

plot_roc_curve(clf, X, y)

