# -*- coding: utf-8 -*-
"""Ztier_predict_tensorflow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ABfvuDvKx9c7NwXH_L-4SsaAO2y72qpa
"""

import tensorflow as tf
import numpy as np
from tensorflow import keras
from tensorflow.keras import layers
!pip install -q seaborn
import pathlib
import numpy as np
import pandas as pd
import seaborn as sns
import os
from sklearn.datasets import make_classification
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import RobustScaler
from sklearn import metrics
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
from sklearn.metrics import plot_roc_curve
from sklearn.metrics import auc
from matplotlib import pyplot
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
import tensorflow_datasets as tfds
from keras.models import load_model

"""**Import Data**"""

from google.colab import files
uploaded = files.upload()

import io
df = pd.read_csv(io.BytesIO(uploaded['Ztier_total.csv']))
# Dataset is now stored in a Pandas Dataframe

"""**Prep Data**"""

del df['MerchantID']
#convert object to float64
df['Average - Short-Term Debt/Equity'] = pd.to_numeric(df['Average - Short-Term Debt/Equity'], errors='coerce')
df['Average - Cash/Net Sales'] = pd.to_numeric(df['Average - Cash/Net Sales'], errors='coerce')
df['Average - Ebit/Sales'] = pd.to_numeric(df['Average - Ebit/Sales'], errors='coerce')
df['Average - Net Income/Sales'] = pd.to_numeric(df['Average - Net Income/Sales'], errors='coerce')
df['Average - Ebitda/Interest Expense'] = pd.to_numeric(df['Average - Ebitda/Interest Expense'], errors='coerce')
df['Average - Ebit/Interest Expenses'] = pd.to_numeric(df['Average - Ebit/Interest Expenses'], errors='coerce')
df['Average - Account Payable/Sales'] = pd.to_numeric(df['Average - Account Payable/Sales'], errors='coerce')
#fill 0 in missing value
df2 = df.fillna(0)

#replace z tier = -1 to 0
df2['Z-score Tier'].replace({-1:0}, inplace=True)

"""Normalized"""

#Normalize
cols_to_normalize=df2.columns[0:29]

df2.info()

col_values=df2[cols_to_normalize].values

col_scaled=RobustScaler().fit_transform(col_values)

df2[cols_to_normalize]=pd.DataFrame(col_scaled,columns=cols_to_normalize)

#check normalize
newdf = df2.agg(['min', 'max','mean'])
newdf

"""**build model**"""

#Split train&test dataset
X=df2[df2.columns[0:29]]

y=df2[df2.columns[-1:]]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)

from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score

"""Test"""

def build_model():
  model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
  ])

  model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),
                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),
                metrics=['accuracy'])
  return model

keras_model = KerasClassifier(build_model)

keras_model._estimator_type = "classifier"

keras_model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)

keras_model.score(X_test, y_test)

keras_model.score(X, y)

"""Backup old model"""

def build_model():
 model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
  ])

  model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),
                loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),
                metrics=['accuracy'])
  return model

keras_model = build_model()

keras_model._estimator_type = "classifier"

keras_model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1)

keras_model.evaluate(X_test, y_test)

keras_model.evaluate(X, y)

"""Save Model"""

keras_model.save("TF_Model.h5")

from google.colab import files
files.download("TF_Model.h5")

"""**Prediction**

ROC
"""

#y_pred_keras = keras_model.predict(X_test).ravel()
y_pred_keras = keras_model.predict(X).ravel()
y_pred=keras_model.predict_classes(X)

fpr_keras, tpr_keras, thresholds_keras = roc_curve(y, y_pred_keras)
#fpr_keras, tpr_keras, thresholds_keras = roc_curve(y, y_pred)

auc_keras = auc(fpr_keras, tpr_keras)

plt.figure(1)
plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras))
plt.xlabel('False positive rate')
plt.ylabel('True positive rate')
plt.title('ROC curve')
plt.legend(loc='best')
plt.show()

"""Confidence"""

pre_pro = keras_model.predict(X)

pp = pd.DataFrame(pre_pro)

pp

"""Confusion Matrix"""

pp.to_csv('confidence.csv')

from google.colab import files
files.download('confidence.csv')

y_predall = pd.DataFrame(y_pred)

y_predall = y_predall[0].values.tolist()

print(metrics.confusion_matrix(y, y_predall))

conf=metrics.confusion_matrix(y, y_predall)

conf=pd.DataFrame(conf)
conf

print(metrics.classification_report(y, y_predall))

y_all = y['Z-score Tier'].values.tolist()

import io
df = pd.read_csv(io.BytesIO(uploaded['Ztier_total.csv']))
dfwithID = df

ID = dfwithID['MerchantID'].tolist()

dataframe = pd.DataFrame([ID, y_all, y_predall], index =['MerchantID', 'y_actual', 'y_predict'])

dataframe = dataframe.T

dataframe.to_csv('Prediction TF.csv')

from google.colab import files
files.download('Prediction TF.csv')

